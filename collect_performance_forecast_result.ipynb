{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "164a4014-3aad-47de-9c62-911d3d5a82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime,date,timedelta,timezone\n",
    "import calendar\n",
    "import json\n",
    "\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70179656-b3c0-4034-b606-9e856e4b62c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collectionDate='2023-09-09 10:00' # comment  # run every week\n",
    "# uncomment and indent\n",
    "# import functions_framework\n",
    "# @functions_framework.http\n",
    "# def collect_prediction_result(request):   # run on clound function\n",
    "\n",
    "# def collect_prediction_result(collectionDate): # backfill\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7e353-6409-4a1e-952e-a1e7375f706f",
   "metadata": {},
   "source": [
    "# Dict To store all collective data Mode To run Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "257e216f-9287-4c5f-9583-de881d10695f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dictCollectPerf={}\n",
    "\n",
    "# uncomment\n",
    "mode=1 # 2 for prodictoin 1 for test/migrate \n",
    "#modelList=['spy-ema1-60t10-ds0115t0523','qqq-ema1-30t5-ds0115t0523','spy-signal-60t10-ds0115t0523']\n",
    "\n",
    "# comment\n",
    "#model_id='spy-ema1-60t10-ds0115t0523'\n",
    "model_id='qqq-ema1-30t5-ds0115t0523'\n",
    "#model_id=\"spy-signal-60t10-ds0115t0523\"\n",
    "\n",
    "# Friday of last n week so we want to collect model perf  0=last week ,1=2 week  \n",
    "# 2=3 is weeks it convert the Friday (last trading day) to have actual value at least  2 week(10day) ahead to compare  predicted value\n",
    "no_week_lookback=2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b906bf-b946-449a-a3a7-94c204799c86",
   "metadata": {},
   "source": [
    "# Init parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec00a87e-4070-4933-9ee4-09b2f986649d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date to collect data on 2023-09-09 Saturday(Idx:5) at 2023-09-09 10:00:00\n",
      "week_day=5 and last_trading_day_of_week=15\n"
     ]
    }
   ],
   "source": [
    "if mode==1: # Backfill data and Test \n",
    "    logDate=collectionDate\n",
    "    log_date=datetime.strptime(logDate,'%Y-%m-%d %H:%M')\n",
    "    log_timestamp=datetime.strptime(logDate,'%Y-%m-%d %H:%M')\n",
    "else: # On weekly basis\n",
    "    log_timestamp=datetime.now(timezone.utc)\n",
    "    log_date=datetime.strptime(log_timestamp.strftime('%Y-%m-%d'),'%Y-%m-%d')\n",
    "\n",
    "week_day=log_date.weekday()\n",
    "day_name=calendar.day_name[log_date.weekday()]\n",
    "\n",
    "print(f\"Date to collect data on {log_date.strftime('%Y-%m-%d')} {day_name}(Idx:{week_day}) at {log_timestamp}\")\n",
    "#week_day=log_date.weekday() Sature=5  [0,1,2,3,4,5,6]\n",
    "\n",
    "\n",
    "if  week_day==5:\n",
    "    last_trading_day_of_week=1+(no_week_lookback*7) # 7 is 1 week\n",
    "    # last_trading_day_of_week=1\n",
    "else:\n",
    "    # comment\n",
    "    raise Exception(\"Saturday is allowed  as Collection Date for forcasting result.\")   \n",
    "    # uncomment\n",
    "    # return \"Saturday is allowed  as Collection Date for forcasting result.\"  \n",
    "\n",
    "print(f\"week_day={week_day} and last_trading_day_of_week={last_trading_day_of_week}\")\n",
    "\n",
    "genTableSchema=False\n",
    "metric_name='mae'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7552d58-047a-4738-804b-490f34468b08",
   "metadata": {},
   "source": [
    "# Create Start to End Date By Getting Last Date of Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a101f2e8-9a65-42b4-b2d7-41b72b835b27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection data from Monday 21-08-2023 to Friday 25-08-2023\n",
      "Convert Start and End Date to gather data 2023-08-21 - 2023-08-25 to string\n"
     ]
    }
   ],
   "source": [
    "# get  prev prediction  from  get end prediction to beginneg or predicton of week \n",
    "endX=log_date+timedelta(days=-last_trading_day_of_week)\n",
    "startX=endX+timedelta(days=1)+timedelta(days=-5) #-5 is from Friday to Monday\n",
    "print(f\"Collection data from {startX.strftime('%A %d-%m-%Y')} to {endX.strftime('%A %d-%m-%Y')}\")\n",
    "\n",
    "endX=endX.strftime('%Y-%m-%d')\n",
    "startX=startX.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Convert Start and End Date to gather data {startX} - {endX} to string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a40750-7bfa-4761-a618-bf8135c0616b",
   "metadata": {},
   "source": [
    "# BigQuery Setting & Configuration Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6630349a-f4ae-4673-8d01-c7a3f842ea17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pongthorn.FinAssetForecast.fin_movement_forecast\n",
      "pongthorn.FinAssetForecast.fin_data\n",
      "pongthorn.FinAssetForecast.model_ts_metadata\n",
      "pongthorn.FinAssetForecast.model2_demo_forecast_performance\n"
     ]
    }
   ],
   "source": [
    "date_col='date'\n",
    "projectId='pongthorn'\n",
    "dataset_id='FinAssetForecast'\n",
    "\n",
    "table_data_id=f\"{projectId}.{dataset_id}.fin_data\"\n",
    "table_id = f\"{projectId}.{dataset_id}.fin_movement_forecast\"\n",
    "table_model_id= f\"{projectId}.{dataset_id}.model_ts_metadata\"\n",
    "\n",
    "\n",
    "#table_perf_id= f\"{projectId}.{dataset_id}.model_forecast_performance\"\n",
    "table_perf_id= f\"{projectId}.{dataset_id}.model2_demo_forecast_performance\"\n",
    "\n",
    "print(table_id)\n",
    "print(table_data_id)\n",
    "print(table_model_id)\n",
    "print(table_perf_id)\n",
    "\n",
    "client = bigquery.Client(project=projectId )\n",
    "\n",
    "def load_data_bq(sql:str):\n",
    "    query_result=client.query(sql)\n",
    "    df=query_result.to_dataframe()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ef5bf-e1f7-4633-a265-9d57e403cc97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce80e154-d966-434f-9213-0c19d719ed83",
   "metadata": {},
   "source": [
    "# Start Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c609e849-435b-400c-ac02-a5249cce9fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect data : spy-ema1-60t10-ds0115t0523 \n"
     ]
    }
   ],
   "source": [
    "# uncomment  and indent\n",
    "# def process_data(model_id):\n",
    "print(f\"Collect data : {model_id} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cafb7e6-e876-4327-9747-8d1181c39881",
   "metadata": {},
   "source": [
    "# Check where the given date collected data or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "421f8e88-996d-41ad-8388-fae8bef117dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "select collection_timestamp from `pongthorn.FinAssetForecast.model2_demo_forecast_performance`\n",
      "where date(collection_timestamp)='2023-09-09' and model_id='spy-ema1-60t10-ds0115t0523'\n",
      "\n",
      "We are ready to Collect data on 2023-09-09 10:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# this version , it will check on each model invidually\n",
    "# you can move it inside def process\n",
    "\n",
    "# script in the first run because we want to generate table with nested and repeated column\n",
    "sqlCheck=f\"\"\"\n",
    "select collection_timestamp from `{table_perf_id}`\n",
    "where date(collection_timestamp)='{log_date.strftime('%Y-%m-%d')}' and model_id='{model_id}'\n",
    "\"\"\"\n",
    "\n",
    "print(sqlCheck)\n",
    "dfCheckDate=load_data_bq(sqlCheck)\n",
    "if  dfCheckDate.empty==False:\n",
    "    print(f\"Collection data on {log_date} for {model_id} found, no any action\")\n",
    "    # uncomment\n",
    "    #return f\"Collection data on {log_date} for {model_id} found, no any action\"\n",
    "else:\n",
    "    print(f\"We are ready to Collect data on {log_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fac79b-f3e3-420c-af2f-a9f2355e3d7d",
   "metadata": {},
   "source": [
    "# Get Model Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6af8a0f4-ebd7-44ce-9317-9eef92d360e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT * FROM `pongthorn.FinAssetForecast.model_ts_metadata`  where model_id='spy-ema1-60t10-ds0115t0523'\n",
      "    \n",
      "model_id                                         spy-ema1-60t10-ds0115t0523\n",
      "asset                                                                   SPY\n",
      "prediction                                                             EMA1\n",
      "input_sequence_length                                                    60\n",
      "output_sequence_length                                                   10\n",
      "gs_model_path                gs://demo-ts-forecast-pongthorn/model_spy_ema1\n",
      "local_model_path                                       model/model_spy_ema1\n",
      "model_file                         EMA1_60To10_SPY_E150S20-Y2015-2023_ma.h5\n",
      "scaler_file                    scaler_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\n",
      "scaler_pred_file          scaler_pred_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def get_model_metadata(model_id):\n",
    "    sqlModelMt=f\"\"\"\n",
    "    SELECT * FROM `{table_model_id}`  where model_id='{model_id}'\n",
    "    \"\"\"\n",
    "    print(sqlModelMt)\n",
    "    dfModelMeta=load_data_bq(sqlModelMt)\n",
    "    return  dfModelMeta\n",
    "\n",
    "dfModelMeta=get_model_metadata(model_id)\n",
    "\n",
    "if dfModelMeta.empty==False:\n",
    "    modelMeta=dfModelMeta.iloc[0,:]\n",
    "    print(modelMeta)\n",
    "    asset_name=modelMeta['asset']\n",
    "    prediction=modelMeta['prediction']\n",
    "else: \n",
    "    raise Exception(f\"Not found model id  {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8201bb-91d8-4e3e-80da-20e7d61b25ba",
   "metadata": {},
   "source": [
    "# Retrive forecasting result data to Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "001948b5-8ef8-46d7-af6e-53b2ef82ce0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Get data from 2023-08-21====to===2023-08-25================\n",
      "1.How far in advance does model want to  make prediction\n",
      "\n",
      "    select t.prediction_date, t.pred_timestamp,t.asset_name,t.prediction_name,\n",
      "    t_pred.output_date as date,t_pred.output_value as EMA1\n",
      "    from  `pongthorn.FinAssetForecast.fin_movement_forecast` t\n",
      "    cross join unnest(t.prediction_result) t_pred\n",
      "    where (t.prediction_date>='2023-08-21' and  t.prediction_date<='2023-08-25')\n",
      "    and t.model_id='spy-ema1-60t10-ds0115t0523'\n",
      "    order by  t.prediction_date,t_pred.output_date\n",
      "    \n",
      "output_sequence_length=50\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 50 entries, 2023-08-22 to 2023-09-11\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   prediction_date  50 non-null     dbdate             \n",
      " 1   pred_timestamp   50 non-null     datetime64[us, UTC]\n",
      " 2   asset_name       50 non-null     object             \n",
      " 3   prediction_name  50 non-null     object             \n",
      " 4   EMA1             50 non-null     float64            \n",
      "dtypes: datetime64[us, UTC](1), dbdate(1), float64(1), object(2)\n",
      "memory usage: 2.3+ KB\n",
      "None\n",
      "           prediction_date asset_name prediction_name        EMA1\n",
      "date                                                             \n",
      "2023-08-22      2023-08-21        SPY            EMA1  444.989990\n",
      "2023-08-23      2023-08-21        SPY            EMA1  440.317657\n",
      "2023-08-24      2023-08-21        SPY            EMA1  441.218964\n",
      "2023-08-25      2023-08-21        SPY            EMA1  438.335083\n",
      "2023-08-28      2023-08-21        SPY            EMA1  442.743866\n",
      "2023-08-29      2023-08-21        SPY            EMA1  440.702881\n",
      "2023-08-30      2023-08-21        SPY            EMA1  440.167419\n",
      "2023-08-31      2023-08-21        SPY            EMA1  442.466125\n",
      "2023-09-01      2023-08-21        SPY            EMA1  438.661865\n",
      "2023-09-05      2023-08-21        SPY            EMA1  439.232788\n",
      "2023-08-23      2023-08-22        SPY            EMA1  444.773926\n",
      "2023-08-24      2023-08-22        SPY            EMA1  440.177277\n",
      "2023-08-25      2023-08-22        SPY            EMA1  441.130737\n",
      "2023-08-28      2023-08-22        SPY            EMA1  438.348602\n",
      "2023-08-29      2023-08-22        SPY            EMA1  442.597382\n",
      "2023-08-30      2023-08-22        SPY            EMA1  440.821320\n",
      "2023-08-31      2023-08-22        SPY            EMA1  440.269440\n",
      "2023-09-01      2023-08-22        SPY            EMA1  442.423035\n",
      "2023-09-05      2023-08-22        SPY            EMA1  438.700989\n",
      "2023-09-06      2023-08-22        SPY            EMA1  439.204437\n",
      "2023-08-24      2023-08-23        SPY            EMA1  445.094208\n",
      "2023-08-25      2023-08-23        SPY            EMA1  440.602936\n",
      "2023-08-28      2023-08-23        SPY            EMA1  441.692841\n",
      "2023-08-29      2023-08-23        SPY            EMA1  439.035858\n",
      "2023-08-30      2023-08-23        SPY            EMA1  443.233185\n",
      "2023-08-31      2023-08-23        SPY            EMA1  441.786621\n",
      "2023-09-01      2023-08-23        SPY            EMA1  441.150818\n",
      "2023-09-05      2023-08-23        SPY            EMA1  443.056885\n",
      "2023-09-06      2023-08-23        SPY            EMA1  439.493225\n",
      "2023-09-07      2023-08-23        SPY            EMA1  439.938019\n",
      "2023-08-25      2023-08-24        SPY            EMA1  444.912720\n",
      "2023-08-28      2023-08-24        SPY            EMA1  440.525238\n",
      "2023-08-29      2023-08-24        SPY            EMA1  441.582947\n",
      "2023-08-30      2023-08-24        SPY            EMA1  438.963379\n",
      "2023-08-31      2023-08-24        SPY            EMA1  442.958313\n",
      "2023-09-01      2023-08-24        SPY            EMA1  441.740814\n",
      "2023-09-05      2023-08-24        SPY            EMA1  441.085602\n",
      "2023-09-06      2023-08-24        SPY            EMA1  443.017548\n",
      "2023-09-07      2023-08-24        SPY            EMA1  439.590912\n",
      "2023-09-08      2023-08-24        SPY            EMA1  439.857513\n",
      "2023-08-28      2023-08-25        SPY            EMA1  444.132690\n",
      "2023-08-29      2023-08-25        SPY            EMA1  439.746307\n",
      "2023-08-30      2023-08-25        SPY            EMA1  440.791321\n",
      "2023-08-31      2023-08-25        SPY            EMA1  438.236755\n",
      "2023-09-01      2023-08-25        SPY            EMA1  442.215393\n",
      "2023-09-05      2023-08-25        SPY            EMA1  441.129333\n",
      "2023-09-06      2023-08-25        SPY            EMA1  440.315704\n",
      "2023-09-07      2023-08-25        SPY            EMA1  442.306366\n",
      "2023-09-08      2023-08-25        SPY            EMA1  439.068085\n",
      "2023-09-11      2023-08-25        SPY            EMA1  439.222565\n",
      "================================================================================================\n",
      "2.Get Real Data  to compare to prediction from 2023-08-22 to 2023-09-11\n",
      "\n",
      "    select Date as date,EMA1, ImportDateTime, from `pongthorn.FinAssetForecast.fin_data` \n",
      "    where (Date>='2023-08-22' and Date<='2023-09-11') and Symbol='SPY'\n",
      "    order by ImportDateTime,Date\n",
      "    \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 13 entries, 2023-08-22 to 2023-09-08\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   EMA1            13 non-null     float64       \n",
      " 1   ImportDateTime  13 non-null     datetime64[us]\n",
      "dtypes: datetime64[us](1), float64(1)\n",
      "memory usage: 312.0 bytes\n",
      "None\n",
      "                EMA1\n",
      "date                \n",
      "2023-08-22  441.4926\n",
      "2023-08-23  441.7721\n",
      "2023-08-24  440.8845\n",
      "2023-08-25  440.7212\n",
      "2023-08-28  441.1001\n",
      "2023-08-29  442.5680\n",
      "2023-08-30  444.1029\n",
      "2023-08-31  445.2388\n",
      "2023-09-01  446.3245\n",
      "2023-09-05  446.8557\n",
      "2023-09-06  446.7401\n",
      "2023-09-07  446.3964\n",
      "2023-09-08  446.2387\n",
      "================================================================================================\n",
      "=======================================================================\n"
     ]
    }
   ],
   "source": [
    "def get_forecasting_result_data(request):\n",
    "\n",
    "    if   request is not None:  \n",
    "        start_date=request[\"start_date\"]\n",
    "        end_date=request[\"end_date\"]\n",
    "        prediction_name=request[\"prediction_name\"]\n",
    "        asset_name=request[\"asset_name\"]\n",
    "        model_id=request[\"model_id\"]\n",
    "    else:\n",
    "        raise Exception(\"No request parameters such as start_date,prediction_name,asset_name\")\n",
    "\n",
    "    \n",
    "    print(\"1.How far in advance does model want to  make prediction\")\n",
    "    sqlOutput=f\"\"\"\n",
    "    select t.prediction_date, t.pred_timestamp,t.asset_name,t.prediction_name,\n",
    "    t_pred.output_date as {date_col},t_pred.output_value as {prediction_name}\n",
    "    from  `{table_id}` t\n",
    "    cross join unnest(t.prediction_result) t_pred\n",
    "    where (t.prediction_date>='{start_date}' and  t.prediction_date<='{end_date}')\n",
    "    and t.model_id='{model_id}'\n",
    "    order by  t.prediction_date,t_pred.output_date\n",
    "    \"\"\"\n",
    "    print(sqlOutput)\n",
    "    dfOutput=load_data_bq(sqlOutput)\n",
    "    # dfOutput=dfOutput.drop_duplicates(subset=[date_col,'asset_name','prediction_name'],keep='last',)\n",
    "    # dfOutput=dfOutput.drop_duplicates(subset=[date_col],keep='last',)\n",
    "    dfOutput[date_col]=pd.to_datetime(dfOutput[date_col],format='%Y-%m-%d')\n",
    "    dfOutput.set_index(date_col,inplace=True)\n",
    "\n",
    "    output_sequence_length=len(dfOutput)\n",
    "    print(f\"output_sequence_length={output_sequence_length}\")\n",
    "    \n",
    "\n",
    "    print(dfOutput.info())\n",
    "    print(dfOutput[['prediction_date','asset_name','prediction_name' ,prediction_name]])\n",
    "    print(\"================================================================================================\")\n",
    "\n",
    "    \n",
    "    #get actual data since the fist day of input and the last day of output(if covered)\n",
    "    startFinData=dfOutput.index.min().strftime('%Y-%m-%d')\n",
    "    endFindData=dfOutput.index.max().strftime('%Y-%m-%d')\n",
    "    print(f\"2.Get Real Data  to compare to prediction from {startFinData} to {endFindData}\")\n",
    "\n",
    "    sqlData=f\"\"\"\n",
    "    select Date as {date_col},{prediction_name}, ImportDateTime, from `{table_data_id}` \n",
    "    where (Date>='{startFinData}' and Date<='{endFindData}') and Symbol='{asset_name}'\n",
    "    order by ImportDateTime,Date\n",
    "    \"\"\"\n",
    "    print(sqlData)\n",
    "\n",
    "    dfRealData=load_data_bq(sqlData)\n",
    "    dfRealData=dfRealData.drop_duplicates(subset=[date_col],keep='last',)\n",
    "    dfRealData[date_col]=pd.to_datetime(dfRealData[date_col],format='%Y-%m-%d')\n",
    "    dfRealData.set_index(date_col,inplace=True)\n",
    "    \n",
    "    print(dfRealData.info())\n",
    "    print(dfRealData[[prediction_name]])\n",
    "    print(\"================================================================================================\")\n",
    "\n",
    "    return {'actual_price':dfRealData,'output':dfOutput }\n",
    "\n",
    "\n",
    "print(f\"================Get data from {startX}====to==={endX}================\")\n",
    "request={'start_date':startX,'end_date':endX,'prediction_name':prediction,'asset_name':asset_name,'model_id':model_id}\n",
    "data=get_forecasting_result_data(request)\n",
    "print(f\"=======================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5051678-ffb7-4d67-be3a-da1ef00d08cb",
   "metadata": {},
   "source": [
    "# Create Predictive and Actual Value dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9785fb22-818b-499f-9fb1-85fb8063d517",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all trading day in the week\n",
      "<DateArray>\n",
      "[datetime.date(2023, 8, 21), datetime.date(2023, 8, 22),\n",
      " datetime.date(2023, 8, 23), datetime.date(2023, 8, 24),\n",
      " datetime.date(2023, 8, 25)]\n",
      "Length: 5, dtype: dbdate\n"
     ]
    }
   ],
   "source": [
    "print(\"List all trading day in the week\")\n",
    "myTradingDataList=data['output']['prediction_date'].unique()\n",
    "print(myTradingDataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b1bf0362-79be-41d0-b2bb-b902707a19bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pred_value</th>\n",
       "      <th>actual_value</th>\n",
       "      <th>prediction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, pred_value, actual_value, prediction_date]\n",
       "Index: []"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAllForecastResult=pd.DataFrame(columns=['date','pred_value','actual_value','prediction_date'])\n",
    "dfAllForecastResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16f6d484-4c53-4a32-b60a-970b11a39e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================dfX :Actual Price========================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 13 entries, 2023-08-22 to 2023-09-08\n",
      "Data columns (total 1 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   actual_value  13 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 208.0 bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-08-22</th>\n",
       "      <td>441.4926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-23</th>\n",
       "      <td>441.7721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-24</th>\n",
       "      <td>440.8845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-25</th>\n",
       "      <td>440.7212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-28</th>\n",
       "      <td>441.1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-29</th>\n",
       "      <td>442.5680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-30</th>\n",
       "      <td>444.1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-31</th>\n",
       "      <td>445.2388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-01</th>\n",
       "      <td>446.3245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-05</th>\n",
       "      <td>446.8557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-06</th>\n",
       "      <td>446.7401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-07</th>\n",
       "      <td>446.3964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-08</th>\n",
       "      <td>446.2387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            actual_value\n",
       "date                    \n",
       "2023-08-22      441.4926\n",
       "2023-08-23      441.7721\n",
       "2023-08-24      440.8845\n",
       "2023-08-25      440.7212\n",
       "2023-08-28      441.1001\n",
       "2023-08-29      442.5680\n",
       "2023-08-30      444.1029\n",
       "2023-08-31      445.2388\n",
       "2023-09-01      446.3245\n",
       "2023-09-05      446.8557\n",
       "2023-09-06      446.7401\n",
       "2023-09-07      446.3964\n",
       "2023-09-08      446.2387"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"========================dfX :Actual Price========================\")\n",
    "dfX=data['actual_price'][[prediction]]\n",
    "dfX.columns=[f'actual_value']\n",
    "print(dfX.info())\n",
    "dfX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8fb89caf-45e7-4339-be0b-12012bb96884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================dfPred:Predicted Price at 2023-08-21=========================\n",
      "            pred_value\n",
      "date                  \n",
      "2023-08-22  444.989990\n",
      "2023-08-23  440.317657\n",
      "2023-08-24  441.218964\n",
      "2023-08-25  438.335083\n",
      "2023-08-28  442.743866\n",
      "2023-08-29  440.702881\n",
      "2023-08-30  440.167419\n",
      "2023-08-31  442.466125\n",
      "2023-09-01  438.661865\n",
      "2023-09-05  439.232788\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 10 entries, 2023-08-22 to 2023-09-05\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   pred_value  10 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 160.0 bytes\n",
      "None\n",
      "=====================dfCompare:Join Actual price to Predicted Price=================\n",
      "        date  pred_value  actual_value prediction_date\n",
      "0 2023-08-22  444.989990      441.4926      2023-08-21\n",
      "1 2023-08-23  440.317657      441.7721      2023-08-21\n",
      "2 2023-08-24  441.218964      440.8845      2023-08-21\n",
      "3 2023-08-25  438.335083      440.7212      2023-08-21\n",
      "4 2023-08-28  442.743866      441.1001      2023-08-21\n",
      "5 2023-08-29  440.702881      442.5680      2023-08-21\n",
      "6 2023-08-30  440.167419      444.1029      2023-08-21\n",
      "7 2023-08-31  442.466125      445.2388      2023-08-21\n",
      "8 2023-09-01  438.661865      446.3245      2023-08-21\n",
      "9 2023-09-05  439.232788      446.8557      2023-08-21\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   date             10 non-null     datetime64[ns]\n",
      " 1   pred_value       10 non-null     float64       \n",
      " 2   actual_value     10 non-null     float64       \n",
      " 3   prediction_date  10 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(1)\n",
      "memory usage: 448.0+ bytes\n",
      "None\n",
      "=========================Appended Data Joined=========================\n",
      "=========================dfPred:Predicted Price at 2023-08-22=========================\n",
      "            pred_value\n",
      "date                  \n",
      "2023-08-23  444.773926\n",
      "2023-08-24  440.177277\n",
      "2023-08-25  441.130737\n",
      "2023-08-28  438.348602\n",
      "2023-08-29  442.597382\n",
      "2023-08-30  440.821320\n",
      "2023-08-31  440.269440\n",
      "2023-09-01  442.423035\n",
      "2023-09-05  438.700989\n",
      "2023-09-06  439.204437\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 10 entries, 2023-08-23 to 2023-09-06\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   pred_value  10 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 160.0 bytes\n",
      "None\n",
      "=====================dfCompare:Join Actual price to Predicted Price=================\n",
      "        date  pred_value  actual_value prediction_date\n",
      "0 2023-08-23  444.773926      441.7721      2023-08-22\n",
      "1 2023-08-24  440.177277      440.8845      2023-08-22\n",
      "2 2023-08-25  441.130737      440.7212      2023-08-22\n",
      "3 2023-08-28  438.348602      441.1001      2023-08-22\n",
      "4 2023-08-29  442.597382      442.5680      2023-08-22\n",
      "5 2023-08-30  440.821320      444.1029      2023-08-22\n",
      "6 2023-08-31  440.269440      445.2388      2023-08-22\n",
      "7 2023-09-01  442.423035      446.3245      2023-08-22\n",
      "8 2023-09-05  438.700989      446.8557      2023-08-22\n",
      "9 2023-09-06  439.204437      446.7401      2023-08-22\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   date             10 non-null     datetime64[ns]\n",
      " 1   pred_value       10 non-null     float64       \n",
      " 2   actual_value     10 non-null     float64       \n",
      " 3   prediction_date  10 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(1)\n",
      "memory usage: 448.0+ bytes\n",
      "None\n",
      "=========================Appended Data Joined=========================\n",
      "=========================dfPred:Predicted Price at 2023-08-23=========================\n",
      "            pred_value\n",
      "date                  \n",
      "2023-08-24  445.094208\n",
      "2023-08-25  440.602936\n",
      "2023-08-28  441.692841\n",
      "2023-08-29  439.035858\n",
      "2023-08-30  443.233185\n",
      "2023-08-31  441.786621\n",
      "2023-09-01  441.150818\n",
      "2023-09-05  443.056885\n",
      "2023-09-06  439.493225\n",
      "2023-09-07  439.938019\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 10 entries, 2023-08-24 to 2023-09-07\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   pred_value  10 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 160.0 bytes\n",
      "None\n",
      "=====================dfCompare:Join Actual price to Predicted Price=================\n",
      "        date  pred_value  actual_value prediction_date\n",
      "0 2023-08-24  445.094208      440.8845      2023-08-23\n",
      "1 2023-08-25  440.602936      440.7212      2023-08-23\n",
      "2 2023-08-28  441.692841      441.1001      2023-08-23\n",
      "3 2023-08-29  439.035858      442.5680      2023-08-23\n",
      "4 2023-08-30  443.233185      444.1029      2023-08-23\n",
      "5 2023-08-31  441.786621      445.2388      2023-08-23\n",
      "6 2023-09-01  441.150818      446.3245      2023-08-23\n",
      "7 2023-09-05  443.056885      446.8557      2023-08-23\n",
      "8 2023-09-06  439.493225      446.7401      2023-08-23\n",
      "9 2023-09-07  439.938019      446.3964      2023-08-23\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   date             10 non-null     datetime64[ns]\n",
      " 1   pred_value       10 non-null     float64       \n",
      " 2   actual_value     10 non-null     float64       \n",
      " 3   prediction_date  10 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(1)\n",
      "memory usage: 448.0+ bytes\n",
      "None\n",
      "=========================Appended Data Joined=========================\n",
      "=========================dfPred:Predicted Price at 2023-08-24=========================\n",
      "            pred_value\n",
      "date                  \n",
      "2023-08-25  444.912720\n",
      "2023-08-28  440.525238\n",
      "2023-08-29  441.582947\n",
      "2023-08-30  438.963379\n",
      "2023-08-31  442.958313\n",
      "2023-09-01  441.740814\n",
      "2023-09-05  441.085602\n",
      "2023-09-06  443.017548\n",
      "2023-09-07  439.590912\n",
      "2023-09-08  439.857513\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 10 entries, 2023-08-25 to 2023-09-08\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   pred_value  10 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 160.0 bytes\n",
      "None\n",
      "=====================dfCompare:Join Actual price to Predicted Price=================\n",
      "        date  pred_value  actual_value prediction_date\n",
      "0 2023-08-25  444.912720      440.7212      2023-08-24\n",
      "1 2023-08-28  440.525238      441.1001      2023-08-24\n",
      "2 2023-08-29  441.582947      442.5680      2023-08-24\n",
      "3 2023-08-30  438.963379      444.1029      2023-08-24\n",
      "4 2023-08-31  442.958313      445.2388      2023-08-24\n",
      "5 2023-09-01  441.740814      446.3245      2023-08-24\n",
      "6 2023-09-05  441.085602      446.8557      2023-08-24\n",
      "7 2023-09-06  443.017548      446.7401      2023-08-24\n",
      "8 2023-09-07  439.590912      446.3964      2023-08-24\n",
      "9 2023-09-08  439.857513      446.2387      2023-08-24\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   date             10 non-null     datetime64[ns]\n",
      " 1   pred_value       10 non-null     float64       \n",
      " 2   actual_value     10 non-null     float64       \n",
      " 3   prediction_date  10 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(1)\n",
      "memory usage: 448.0+ bytes\n",
      "None\n",
      "=========================Appended Data Joined=========================\n",
      "=========================dfPred:Predicted Price at 2023-08-25=========================\n",
      "            pred_value\n",
      "date                  \n",
      "2023-08-28  444.132690\n",
      "2023-08-29  439.746307\n",
      "2023-08-30  440.791321\n",
      "2023-08-31  438.236755\n",
      "2023-09-01  442.215393\n",
      "2023-09-05  441.129333\n",
      "2023-09-06  440.315704\n",
      "2023-09-07  442.306366\n",
      "2023-09-08  439.068085\n",
      "2023-09-11  439.222565\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 10 entries, 2023-08-28 to 2023-09-11\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   pred_value  10 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 160.0 bytes\n",
      "None\n",
      "=====================dfCompare:Join Actual price to Predicted Price=================\n",
      "        date  pred_value  actual_value prediction_date\n",
      "0 2023-08-28  444.132690      441.1001      2023-08-25\n",
      "1 2023-08-29  439.746307      442.5680      2023-08-25\n",
      "2 2023-08-30  440.791321      444.1029      2023-08-25\n",
      "3 2023-08-31  438.236755      445.2388      2023-08-25\n",
      "4 2023-09-01  442.215393      446.3245      2023-08-25\n",
      "5 2023-09-05  441.129333      446.8557      2023-08-25\n",
      "6 2023-09-06  440.315704      446.7401      2023-08-25\n",
      "7 2023-09-07  442.306366      446.3964      2023-08-25\n",
      "8 2023-09-08  439.068085      446.2387      2023-08-25\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   date             9 non-null      datetime64[ns]\n",
      " 1   pred_value       9 non-null      float64       \n",
      " 2   actual_value     9 non-null      float64       \n",
      " 3   prediction_date  9 non-null      object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(1)\n",
      "memory usage: 416.0+ bytes\n",
      "None\n",
      "=========================Appended Data Joined=========================\n"
     ]
    }
   ],
   "source": [
    "# actually , we can jon without spilting data by prediction_dtate\n",
    "for date in  myTradingDataList: # trading day on giver week\n",
    "    print(f\"=========================dfPred:Predicted Price at {date}=========================\")\n",
    "    dfPred=data['output'].query(\"prediction_date==@date\")[[prediction]]\n",
    "    dfPred.columns=[f'pred_value']\n",
    "    print(dfPred)\n",
    "    print(dfPred.info())\n",
    "\n",
    "    print(\"=====================dfCompare:Join Actual price to Predicted Price=================\")\n",
    "    dfCompare=pd.merge(left=dfPred,right=dfX,how='inner',right_index=True,left_index=True)\n",
    "    dfCompare.reset_index(inplace=True)   \n",
    "    dfCompare['prediction_date']=date.strftime('%Y-%m-%d')      \n",
    "    print(dfCompare) \n",
    "    print(dfCompare.info())\n",
    "\n",
    "    if len(dfCompare)>0 : # it will be join if there is at least one record to show actual vs pred\n",
    "        dfAllForecastResult= pd.concat([dfAllForecastResult,dfCompare],ignore_index=True)\n",
    "        print(f\"=========================Appended Data Joined=========================\")\n",
    "    else:\n",
    "        print(\"No Appendind Data due to no at least one record to show actual vs pred\")  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "70da4df5-d4df-406f-825e-b0eda85f00ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================dfAllForecastResult: All Predicton Result========================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49 entries, 0 to 48\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   date             49 non-null     datetime64[ns]\n",
      " 1   pred_value       49 non-null     float64       \n",
      " 2   actual_value     49 non-null     float64       \n",
      " 3   prediction_date  49 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(1)\n",
      "memory usage: 1.7+ KB\n",
      "None\n",
      "         date  pred_value  actual_value prediction_date\n",
      "0  2023-08-22  444.989990      441.4926      2023-08-21\n",
      "1  2023-08-23  440.317657      441.7721      2023-08-21\n",
      "2  2023-08-24  441.218964      440.8845      2023-08-21\n",
      "3  2023-08-25  438.335083      440.7212      2023-08-21\n",
      "4  2023-08-28  442.743866      441.1001      2023-08-21\n",
      "5  2023-08-29  440.702881      442.5680      2023-08-21\n",
      "6  2023-08-30  440.167419      444.1029      2023-08-21\n",
      "7  2023-08-31  442.466125      445.2388      2023-08-21\n",
      "8  2023-09-01  438.661865      446.3245      2023-08-21\n",
      "9  2023-09-05  439.232788      446.8557      2023-08-21\n",
      "10 2023-08-23  444.773926      441.7721      2023-08-22\n",
      "11 2023-08-24  440.177277      440.8845      2023-08-22\n",
      "12 2023-08-25  441.130737      440.7212      2023-08-22\n",
      "13 2023-08-28  438.348602      441.1001      2023-08-22\n",
      "14 2023-08-29  442.597382      442.5680      2023-08-22\n",
      "15 2023-08-30  440.821320      444.1029      2023-08-22\n",
      "16 2023-08-31  440.269440      445.2388      2023-08-22\n",
      "17 2023-09-01  442.423035      446.3245      2023-08-22\n",
      "18 2023-09-05  438.700989      446.8557      2023-08-22\n",
      "19 2023-09-06  439.204437      446.7401      2023-08-22\n",
      "20 2023-08-24  445.094208      440.8845      2023-08-23\n",
      "21 2023-08-25  440.602936      440.7212      2023-08-23\n",
      "22 2023-08-28  441.692841      441.1001      2023-08-23\n",
      "23 2023-08-29  439.035858      442.5680      2023-08-23\n",
      "24 2023-08-30  443.233185      444.1029      2023-08-23\n",
      "25 2023-08-31  441.786621      445.2388      2023-08-23\n",
      "26 2023-09-01  441.150818      446.3245      2023-08-23\n",
      "27 2023-09-05  443.056885      446.8557      2023-08-23\n",
      "28 2023-09-06  439.493225      446.7401      2023-08-23\n",
      "29 2023-09-07  439.938019      446.3964      2023-08-23\n",
      "30 2023-08-25  444.912720      440.7212      2023-08-24\n",
      "31 2023-08-28  440.525238      441.1001      2023-08-24\n",
      "32 2023-08-29  441.582947      442.5680      2023-08-24\n",
      "33 2023-08-30  438.963379      444.1029      2023-08-24\n",
      "34 2023-08-31  442.958313      445.2388      2023-08-24\n",
      "35 2023-09-01  441.740814      446.3245      2023-08-24\n",
      "36 2023-09-05  441.085602      446.8557      2023-08-24\n",
      "37 2023-09-06  443.017548      446.7401      2023-08-24\n",
      "38 2023-09-07  439.590912      446.3964      2023-08-24\n",
      "39 2023-09-08  439.857513      446.2387      2023-08-24\n",
      "40 2023-08-28  444.132690      441.1001      2023-08-25\n",
      "41 2023-08-29  439.746307      442.5680      2023-08-25\n",
      "42 2023-08-30  440.791321      444.1029      2023-08-25\n",
      "43 2023-08-31  438.236755      445.2388      2023-08-25\n",
      "44 2023-09-01  442.215393      446.3245      2023-08-25\n",
      "45 2023-09-05  441.129333      446.8557      2023-08-25\n",
      "46 2023-09-06  440.315704      446.7401      2023-08-25\n",
      "47 2023-09-07  442.306366      446.3964      2023-08-25\n",
      "48 2023-09-08  439.068085      446.2387      2023-08-25\n"
     ]
    }
   ],
   "source": [
    "print(\"========================dfAllForecastResult: All Predicton Result========================\")\n",
    "print(dfAllForecastResult.info())\n",
    "print(dfAllForecastResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56adbf50-b5f9-4788-a1d1-e15effc86e3f",
   "metadata": {},
   "source": [
    "# Calculate MAE Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200bb009-2934-403c-99be-f18c8231a1cc",
   "metadata": {},
   "source": [
    "## Get sum distance between pred and actul value from prev rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7f072e08-3757-4ce5-9564-7b6c9a09ab0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "with pred_actual_by_model as  \n",
      "(\n",
      "SELECT  detail.actual_value,detail.pred_value\n",
      "from `pongthorn.FinAssetForecast.model2_demo_forecast_performance`  t\n",
      " cross join unnest(t.pred_actual_data) as detail\n",
      " where t.model_id='spy-ema1-60t10-ds0115t0523' and t.collection_timestamp<'2023-09-09 10:00:00'\n",
      ")\n",
      "select COALESCE( sum(abs(x.actual_value-x.pred_value)),0) as pred_diff_actual,count(*) as no_row  from pred_actual_by_model  x\n",
      "\n",
      "\n",
      "\n",
      "Prev Sum=577.9779383302005 and Count=150\n"
     ]
    }
   ],
   "source": [
    "sqlMetric=f\"\"\"\n",
    "with pred_actual_by_model as  \n",
    "(\n",
    "SELECT  detail.actual_value,detail.pred_value\n",
    "from `{table_perf_id}`  t\n",
    " cross join unnest(t.pred_actual_data) as detail\n",
    " where t.model_id='{model_id}' and t.collection_timestamp<'{log_timestamp}'\n",
    ")\n",
    "select COALESCE( sum(abs(x.actual_value-x.pred_value)),0) as pred_diff_actual,count(*) as no_row  from pred_actual_by_model  x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if genTableSchema==False:\n",
    "    print(sqlMetric)\n",
    "\n",
    "    dfMetric=load_data_bq(sqlMetric)\n",
    "    prevSum=dfMetric.iloc[0,0]\n",
    "    prevCount=dfMetric.iloc[0,1]\n",
    "\n",
    "else:  # it is used if there are something changed in table schema\n",
    "# for generating table schema\n",
    "    prevSum=0\n",
    "    prevCount=0\n",
    "\n",
    "print(f\"Prev Sum={prevSum} and Count={prevCount}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c5e088-d020-45c8-a9a8-4e9407906acd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cal sum distance between pred and actul value from last rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "14805124-ae5a-4757-a1d4-376b77b4975d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pred_value</th>\n",
       "      <th>actual_value</th>\n",
       "      <th>prediction_date</th>\n",
       "      <th>pred_diff_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>444.989990</td>\n",
       "      <td>441.4926</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>3.497390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>440.317657</td>\n",
       "      <td>441.7721</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>1.454443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>441.218964</td>\n",
       "      <td>440.8845</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>0.334464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>438.335083</td>\n",
       "      <td>440.7212</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>2.386117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>442.743866</td>\n",
       "      <td>441.1001</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>1.643766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>440.702881</td>\n",
       "      <td>442.5680</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>1.865119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>440.167419</td>\n",
       "      <td>444.1029</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>3.935481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>442.466125</td>\n",
       "      <td>445.2388</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>2.772675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>438.661865</td>\n",
       "      <td>446.3245</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>7.662635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-09-05</td>\n",
       "      <td>439.232788</td>\n",
       "      <td>446.8557</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>7.622912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>444.773926</td>\n",
       "      <td>441.7721</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>3.001826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>440.177277</td>\n",
       "      <td>440.8845</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>0.707223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>441.130737</td>\n",
       "      <td>440.7212</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>0.409537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>438.348602</td>\n",
       "      <td>441.1001</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>2.751498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>442.597382</td>\n",
       "      <td>442.5680</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>0.029382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>440.821320</td>\n",
       "      <td>444.1029</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>3.281580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>440.269440</td>\n",
       "      <td>445.2388</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>4.969360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>442.423035</td>\n",
       "      <td>446.3245</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>3.901465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-09-05</td>\n",
       "      <td>438.700989</td>\n",
       "      <td>446.8557</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>8.154711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>439.204437</td>\n",
       "      <td>446.7401</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>7.535663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>445.094208</td>\n",
       "      <td>440.8845</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>4.209708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>440.602936</td>\n",
       "      <td>440.7212</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>0.118264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>441.692841</td>\n",
       "      <td>441.1001</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>0.592741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>439.035858</td>\n",
       "      <td>442.5680</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>3.532142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>443.233185</td>\n",
       "      <td>444.1029</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>0.869715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>441.786621</td>\n",
       "      <td>445.2388</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>3.452179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>441.150818</td>\n",
       "      <td>446.3245</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>5.173682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-09-05</td>\n",
       "      <td>443.056885</td>\n",
       "      <td>446.8557</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>3.798815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>439.493225</td>\n",
       "      <td>446.7401</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>7.246875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-09-07</td>\n",
       "      <td>439.938019</td>\n",
       "      <td>446.3964</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>6.458381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>444.912720</td>\n",
       "      <td>440.7212</td>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>4.191520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>440.525238</td>\n",
       "      <td>441.1001</td>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>0.574862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>441.582947</td>\n",
       "      <td>442.5680</td>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>0.985053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>438.963379</td>\n",
       "      <td>444.1029</td>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>5.139521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>442.958313</td>\n",
       "      <td>445.2388</td>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>2.280487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>441.740814</td>\n",
       "      <td>446.3245</td>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>4.583686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2023-09-05</td>\n",
       "      <td>441.085602</td>\n",
       "      <td>446.8557</td>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>5.770098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>443.017548</td>\n",
       "      <td>446.7401</td>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>3.722552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2023-09-07</td>\n",
       "      <td>439.590912</td>\n",
       "      <td>446.3964</td>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>6.805488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>439.857513</td>\n",
       "      <td>446.2387</td>\n",
       "      <td>2023-08-24</td>\n",
       "      <td>6.381187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>444.132690</td>\n",
       "      <td>441.1001</td>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>3.032590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>439.746307</td>\n",
       "      <td>442.5680</td>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>2.821693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>440.791321</td>\n",
       "      <td>444.1029</td>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>3.311579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>438.236755</td>\n",
       "      <td>445.2388</td>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>7.002045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>442.215393</td>\n",
       "      <td>446.3245</td>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>4.109107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2023-09-05</td>\n",
       "      <td>441.129333</td>\n",
       "      <td>446.8557</td>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>5.726367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>440.315704</td>\n",
       "      <td>446.7401</td>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>6.424396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2023-09-07</td>\n",
       "      <td>442.306366</td>\n",
       "      <td>446.3964</td>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>4.090034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>439.068085</td>\n",
       "      <td>446.2387</td>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>7.170615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  pred_value  actual_value prediction_date  pred_diff_actual\n",
       "0  2023-08-22  444.989990      441.4926      2023-08-21          3.497390\n",
       "1  2023-08-23  440.317657      441.7721      2023-08-21          1.454443\n",
       "2  2023-08-24  441.218964      440.8845      2023-08-21          0.334464\n",
       "3  2023-08-25  438.335083      440.7212      2023-08-21          2.386117\n",
       "4  2023-08-28  442.743866      441.1001      2023-08-21          1.643766\n",
       "5  2023-08-29  440.702881      442.5680      2023-08-21          1.865119\n",
       "6  2023-08-30  440.167419      444.1029      2023-08-21          3.935481\n",
       "7  2023-08-31  442.466125      445.2388      2023-08-21          2.772675\n",
       "8  2023-09-01  438.661865      446.3245      2023-08-21          7.662635\n",
       "9  2023-09-05  439.232788      446.8557      2023-08-21          7.622912\n",
       "10 2023-08-23  444.773926      441.7721      2023-08-22          3.001826\n",
       "11 2023-08-24  440.177277      440.8845      2023-08-22          0.707223\n",
       "12 2023-08-25  441.130737      440.7212      2023-08-22          0.409537\n",
       "13 2023-08-28  438.348602      441.1001      2023-08-22          2.751498\n",
       "14 2023-08-29  442.597382      442.5680      2023-08-22          0.029382\n",
       "15 2023-08-30  440.821320      444.1029      2023-08-22          3.281580\n",
       "16 2023-08-31  440.269440      445.2388      2023-08-22          4.969360\n",
       "17 2023-09-01  442.423035      446.3245      2023-08-22          3.901465\n",
       "18 2023-09-05  438.700989      446.8557      2023-08-22          8.154711\n",
       "19 2023-09-06  439.204437      446.7401      2023-08-22          7.535663\n",
       "20 2023-08-24  445.094208      440.8845      2023-08-23          4.209708\n",
       "21 2023-08-25  440.602936      440.7212      2023-08-23          0.118264\n",
       "22 2023-08-28  441.692841      441.1001      2023-08-23          0.592741\n",
       "23 2023-08-29  439.035858      442.5680      2023-08-23          3.532142\n",
       "24 2023-08-30  443.233185      444.1029      2023-08-23          0.869715\n",
       "25 2023-08-31  441.786621      445.2388      2023-08-23          3.452179\n",
       "26 2023-09-01  441.150818      446.3245      2023-08-23          5.173682\n",
       "27 2023-09-05  443.056885      446.8557      2023-08-23          3.798815\n",
       "28 2023-09-06  439.493225      446.7401      2023-08-23          7.246875\n",
       "29 2023-09-07  439.938019      446.3964      2023-08-23          6.458381\n",
       "30 2023-08-25  444.912720      440.7212      2023-08-24          4.191520\n",
       "31 2023-08-28  440.525238      441.1001      2023-08-24          0.574862\n",
       "32 2023-08-29  441.582947      442.5680      2023-08-24          0.985053\n",
       "33 2023-08-30  438.963379      444.1029      2023-08-24          5.139521\n",
       "34 2023-08-31  442.958313      445.2388      2023-08-24          2.280487\n",
       "35 2023-09-01  441.740814      446.3245      2023-08-24          4.583686\n",
       "36 2023-09-05  441.085602      446.8557      2023-08-24          5.770098\n",
       "37 2023-09-06  443.017548      446.7401      2023-08-24          3.722552\n",
       "38 2023-09-07  439.590912      446.3964      2023-08-24          6.805488\n",
       "39 2023-09-08  439.857513      446.2387      2023-08-24          6.381187\n",
       "40 2023-08-28  444.132690      441.1001      2023-08-25          3.032590\n",
       "41 2023-08-29  439.746307      442.5680      2023-08-25          2.821693\n",
       "42 2023-08-30  440.791321      444.1029      2023-08-25          3.311579\n",
       "43 2023-08-31  438.236755      445.2388      2023-08-25          7.002045\n",
       "44 2023-09-01  442.215393      446.3245      2023-08-25          4.109107\n",
       "45 2023-09-05  441.129333      446.8557      2023-08-25          5.726367\n",
       "46 2023-09-06  440.315704      446.7401      2023-08-25          6.424396\n",
       "47 2023-09-07  442.306366      446.3964      2023-08-25          4.090034\n",
       "48 2023-09-08  439.068085      446.2387      2023-08-25          7.170615"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAllForecastResult['pred_diff_actual']=dfAllForecastResult.apply(lambda x : abs(x['pred_value']-x['actual_value']),axis=1)\n",
    "dfAllForecastResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8a5df647-fbeb-4523-a087-636bb2d6afbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent Sum=187.49262739270011 and Count=49\n"
     ]
    }
   ],
   "source": [
    "recentSum=dfAllForecastResult['pred_diff_actual'].sum()\n",
    "recentCount=len(dfAllForecastResult)\n",
    "\n",
    "\n",
    "dfAllForecastResult=dfAllForecastResult.drop(columns=['pred_diff_actual'])\n",
    "print(f\"Recent Sum={recentSum} and Count={recentCount}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ff38e5-9f87-4e91-ae14-606bfb690126",
   "metadata": {},
   "source": [
    "## Calculate MEA as formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7d7ffc03-db16-4c83-b897-e454134c6761",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae = 3.85\n"
     ]
    }
   ],
   "source": [
    "#https://en.wikipedia.org/wiki/Mean_absolute_error\n",
    "metric_value= round((prevSum+recentSum)/(prevCount+recentCount),2)\n",
    "print(f\"{metric_name} = {metric_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec25219-a1f1-4c3a-a018-0de174dfc669",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Collection Performance Info Dataframe and Store \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fd483982-7abe-481c-8167-1c72f8409981",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   collection_date       1 non-null      datetime64[ns]\n",
      " 1   model_id              1 non-null      object        \n",
      " 2   metric_name           1 non-null      object        \n",
      " 3   metric_value          1 non-null      float64       \n",
      " 4   collection_timestamp  1 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(1), object(2)\n",
      "memory usage: 168.0+ bytes\n",
      "None\n",
      "      collection_date                    model_id metric_name  metric_value  \\\n",
      "0 2023-09-09 10:00:00  spy-ema1-60t10-ds0115t0523         mae          3.85   \n",
      "\n",
      "  collection_timestamp  \n",
      "0  2023-09-09 10:00:00  \n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(data=[ [log_date,model_id,metric_name,metric_value,log_timestamp] ],\n",
    "                columns=[\"collection_date\",\"model_id\",\"metric_name\",\"metric_value\",\"collection_timestamp\"])\n",
    "print(df.info())\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d6f7c353-748e-4500-b9b8-d699b936b5a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dictCollectPerf[model_id]=(df,dfAllForecastResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "80938791-97c6-418b-b8ef-2b7ba22f75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment\n",
    "#return f\"gather data of {model_id}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd8275-9727-4bcf-a4b0-2896df68a404",
   "metadata": {},
   "source": [
    "# End Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0b8ac5f9-c720-4f56-aba8-912f19c244f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over model list\n",
    "# uncomment\n",
    "# for modelID in modelList:\n",
    "# # indent\n",
    "#   print(process_data(modelID))\n",
    "#   print(\"#########################################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ffae7-8549-4e7c-b919-b90ce1f920e0",
   "metadata": {},
   "source": [
    "# Create Json Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c6c87e63-04de-4c19-a831-26fc21241612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spy-ema1-60t10-ds0115t0523\n"
     ]
    }
   ],
   "source": [
    "jsonDataList=[]\n",
    "for model_id,dataTuple in  dictCollectPerf.items():\n",
    "    print(model_id)\n",
    "    \n",
    "    masterDF=dataTuple[0]\n",
    "    masterDF[\"collection_date\"]=masterDF[\"collection_date\"].dt.strftime('%Y-%m-%d')\n",
    "    masterDF[\"collection_timestamp\"]=masterDF[\"collection_timestamp\"].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    master_perf = json.loads(masterDF.to_json(orient = 'records'))[0] # 1 main dataframe has 1 records\n",
    "    \n",
    "    detailDF=dataTuple[1]  \n",
    "    # print(detailDF.info())\n",
    "    \n",
    "    #detailDF[\"prediction_date\"]=detailDF[\"prediction_date\"].dt.strftime('%Y-%m-%d')\n",
    "    detailDF[\"date\"]=detailDF[\"date\"].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    detail_perf= json.loads(detailDF.to_json(orient = 'records'))\n",
    "    master_perf[\"pred_actual_data\"]=detail_perf\n",
    "    \n",
    "    jsonDataList.append(master_perf)\n",
    "    \n",
    "with open(\"fin_forecast_performance.json\", \"w\") as outfile:\n",
    "    json.dump( jsonDataList, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083681a-8987-4bea-93b2-d6d52aac936c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8bb797d-d12d-48d7-9787-384823c9ddf3",
   "metadata": {},
   "source": [
    "# Ingest Data to BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc85496-fac5-406a-a281-822cae395bf9",
   "metadata": {},
   "source": [
    "## Try to ingest data to get correct schema and copy the schema to create table including partion/cluster manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "55f9ae69-3b55-4347-b2b9-1f74e3c59fee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table pongthorn.FinAssetForecast.model2_demo_forecast_performance already exists.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    table=client.get_table(table_perf_id)\n",
    "    print(\"Table {} already exists.\".format(table_perf_id))\n",
    "    # print(table.schema)\n",
    "except Exception as ex :\n",
    "    print(str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7a8fddac-312e-400e-8b55-6391b73559b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import to bigquery successfully  1 records\n"
     ]
    }
   ],
   "source": [
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "\n",
    "job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "\n",
    "# Try to ingest data to get correct schema and copy the schema to create table including partiion/cluster manually\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND \n",
    "\n",
    "\n",
    "job = client.load_table_from_json(jsonDataList,table_perf_id, job_config = job_config)\n",
    "if job.errors is not None:\n",
    "    print(job.error_result)\n",
    "    print(job.errors)\n",
    "    # uncomment\n",
    "    # return \"Error to load data to BigQuery\"\n",
    "else:\n",
    "    print(f\"Import to bigquery successfully  {len(jsonDataList)} records\")\n",
    "    \n",
    "#job_config.schema\n",
    "# truncate table`pongthorn.FinAssetForecast.model_forecast_performance` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f54298d5-6437-40ac-bbc7-ea2ff03eae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment\n",
    "#return 'completely'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b6fa76-afff-421f-ba7a-9fb587776730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e5c796-ff17-4fd3-8b33-21dfccce4321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment\n",
    "# Main \n",
    "# print(\"Collect prediction result to monitor performance model\")\n",
    "start_backfill='2023-06-03 10:00' # comment\n",
    "end_backfill='2023-08-26 10:00'\n",
    "period_index=pd.date_range(start=start_backfill,end=end_backfill, freq=\"W-SAT\")\n",
    "listLogDate=[ d.strftime('%Y-%m-%d %H:%M')   for  d in  period_index   ]\n",
    "for d in listLogDate:\n",
    "    print(d)\n",
    "# multiple items\n",
    "\n",
    "# listLogDate=[\n",
    "#      '2023-08-05 00:00','2023-08-12 00:00','2023-08-19 00:00','2023-08-26 00:00','2023-09-02 00:00'\n",
    "# ]\n",
    "# for  d in listLogDate:\n",
    "#   print(f\"*******************************Collect prediction result as of {d}*****************************************\")\n",
    "#   print(collect_prediction_result(d))\n",
    "#   print(\"************************************************************************************************\")\n",
    "\n",
    "# sigle item\n",
    "# collectionDate='2023-08-26 00:00' # comment    \n",
    "# print(collect_prediction_result(collectionDate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee397d-ca12-4600-a26e-cb9dc4deb32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
