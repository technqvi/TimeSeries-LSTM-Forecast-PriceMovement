{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9cb56bd-3c45-4f45-a2fb-c33f5198d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime,date,timedelta,timezone\n",
    "import pytz\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103dd64a-6c76-4653-a504-5ba44bb56dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf04c4-e1ce-4eb2-b82c-8b98bae04d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following section\n",
    "# fuction\n",
    "# json and env if/else\n",
    "# return statment\n",
    "\n",
    "# import functions_framework\n",
    "# @functions_framework.http\n",
    "# def forecast_asset_movement(request):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de071b2-41b2-40db-ab1d-7743faa0199f",
   "metadata": {},
   "source": [
    "# Constant & Parameter Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55257eb9-7ddb-4aa6-8d11-bc42344a6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadModelMode='local'   # local,gcs\n",
    "\n",
    "#today='2023-05-31' # last record of training data to predict the first movement\n",
    "today='2023-08-25'\n",
    "model_id='spy-ema1-60t10-ds0115t0523'\n",
    "\n",
    "input_sequence_length =60\n",
    "output_sequence_length =10\n",
    "\n",
    "# if request.get_json():\n",
    "#     print(\"JSON Post Date Info\") # Post Method\n",
    "#     request_json = request.get_json()\n",
    "#     today=request_json['TODAY']\n",
    "#     model_id=request_json['MODEL_ID']\n",
    "\n",
    "# else:\n",
    "#     print(\"Enviroment Variable Info\")\n",
    "#     today=os.environ.get('TODAY', '') \n",
    "#     #today=os.environ.get('TODAY', '2023-04-28')  \n",
    "#     model_id=os.environ.get('MODEL_ID', 'spy-ema1-60t10-ds0115t0523')  \n",
    " \n",
    "\n",
    "print(\"List parameter as belows\")\n",
    "print(f\"today={today}\")\n",
    "print(f\"model_id={model_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e81398-c118-43c5-8a1e-68cfbd0d5ea2",
   "metadata": {},
   "source": [
    "# BigQuery Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cabd15-5e81-4075-a4a7-9aba2ebff632",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectId='pongthorn'\n",
    "dataset_id='FinAssetForecast'\n",
    "table_data_id = f\"{projectId}.{dataset_id}.fin_data\"\n",
    "table_id = f\"{projectId}.{dataset_id}.fin_movement_forecast\"\n",
    "\n",
    "table_model_id= f\"{projectId}.{dataset_id}.model_ts_metadata\"\n",
    "\n",
    "print(table_id)\n",
    "print(table_data_id)\n",
    "print(table_model_id)\n",
    "\n",
    "client = bigquery.Client(project=projectId )\n",
    "\n",
    "def load_data_bq(sql:str):\n",
    " query_result=client.query(sql)\n",
    " df=query_result.to_dataframe()\n",
    " return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a7f48-7759-48bf-8806-089595651be4",
   "metadata": {},
   "source": [
    "# Load Model  Configuration MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7549f76c-4efe-49a5-b201-ba34b58e7172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT * FROM `pongthorn.FinAssetForecast.model_ts_metadata`  where model_id='spy-ema1-60t10-ds0115t0523'\n",
      "\n",
      "model_id                                         spy-ema1-60t10-ds0115t0523\n",
      "asset                                                                   SPY\n",
      "prediction                                                             EMA1\n",
      "input_sequence_length                                                    60\n",
      "output_sequence_length                                                   10\n",
      "gs_model_path                gs://demo-ts-forecast-pongthorn/model_spy_ema1\n",
      "local_model_path                                       model/model_spy_ema1\n",
      "model_file                         EMA1_60To10_SPY_E150S20-Y2015-2023_ma.h5\n",
      "scaler_file                    scaler_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\n",
      "scaler_pred_file          scaler_pred_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sqlModelMt=f\"\"\"\n",
    "SELECT * FROM `{table_model_id}`  where model_id='{model_id}'\n",
    "\"\"\"\n",
    "print(sqlModelMt)\n",
    "dfModelMeta=load_data_bq(sqlModelMt)\n",
    "if dfModelMeta.empty==False:\n",
    "    modelMeta=dfModelMeta.iloc[0,:]\n",
    "    asset_name=modelMeta['asset']\n",
    "    prediction_name=modelMeta['prediction']\n",
    "    \n",
    "    input_sequence_length=int(modelMeta['input_sequence_length'])\n",
    "    output_sequence_length=int(modelMeta['output_sequence_length'])\n",
    "    \n",
    "    model_path=modelMeta['gs_model_path']\n",
    "    local_model_path=modelMeta['local_model_path']\n",
    "    \n",
    "    model_file=modelMeta['model_file']\n",
    "    scaler_file=modelMeta['scaler_file']\n",
    "    scalerPred_file=modelMeta['scaler_pred_file']\n",
    "    print(modelMeta)\n",
    "    \n",
    "else: \n",
    "    raise Exception(f\"Not found model id  {model_id}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c90459-6931-49f7-9908-aaf7e99699bc",
   "metadata": {},
   "source": [
    "# Load model and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2765c501-77a0-45bd-8cec-1f404d31ad00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from local\n",
      "model/model_spy_ema1/EMA1_60To10_SPY_E150S20-Y2015-2023_ma.h5\n",
      "model/model_spy_ema1/scaler_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\n",
      "model/model_spy_ema1/scaler_pred_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\n"
     ]
    }
   ],
   "source": [
    "if loadModelMode=='local':\n",
    " objectPaht=local_model_path\n",
    "else:\n",
    " objectPaht=model_path  \n",
    "\n",
    "model_path=f\"{objectPaht}/{model_file}\"\n",
    "scale_input_path=f\"{objectPaht}/{scaler_file}\"\n",
    "scale_output_path=f\"{objectPaht}/{scalerPred_file}\"\n",
    "\n",
    "print(f\"load model from {loadModelMode}\")   \n",
    "print(model_path)\n",
    "print(scale_input_path)\n",
    "print(scale_output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443426bb-6329-48d8-9c1b-f5a51c31b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadModelMode=='local':\n",
    "    try:\n",
    "        print(\"Model and Scaler Object Summary\")\n",
    "        x_model = load_model(model_path)\n",
    " \n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        raise Exception(str(ex)) \n",
    "    \n",
    "    try:\n",
    "        print(\"Scaler Max-Min\")\n",
    "        x_scaler = joblib.load(scale_input_path)\n",
    "        x_scalerPred=joblib.load(scale_output_path)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        raise Exception(str(ex))\n",
    "\n",
    "    print(\"=====================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "205bf465-9f2b-417c-86aa-22a5062f4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "if loadModelMode=='gcs':\n",
    " try:\n",
    "    gcs_client = storage.Client()\n",
    "\n",
    "    with open(scaler_file, 'wb') as scaler_f, open(scalerPred_file, 'wb') as scaler_pred_f,open(model_file, 'wb') as model_f:\n",
    "        gcs_client.download_blob_to_file(scale_input_path, scaler_f\n",
    "        )\n",
    "        gcs_client.download_blob_to_file(scale_output_path, scaler_pred_f\n",
    "        )\n",
    "        gcs_client.download_blob_to_file(model_path, model_f\n",
    "        )\n",
    "\n",
    "    x_scaler = joblib.load(scaler_file)\n",
    "    x_scalerPred=joblib.load(scalerPred_file)\n",
    "    x_model = load_model(model_file)\n",
    " except Exception as ex:\n",
    "    print(str(ex))\n",
    "    raise Exception(str(ex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4cbc6a3f-8264-4b1d-9424-34a3cf16177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 180)               131040    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 180)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1810      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,850\n",
      "Trainable params: 132,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "max=[473.99] and min=[187.09] and scale=[0.00348554]\n",
      "max=[473.99] and min=[187.09] and scale=[0.00348554]\n"
     ]
    }
   ],
   "source": [
    "print(x_model.summary())\n",
    "#(max - min) / (X.max(axis=0) - X.min(axis=0))\n",
    "print(f\"max={x_scaler.data_max_} and min={x_scaler.data_min_} and scale={x_scaler.scale_}\")\n",
    "print(f\"max={x_scalerPred.data_max_} and min={x_scalerPred.data_min_} and scale={x_scalerPred.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb99063-ed8b-44a9-9bd4-6d708f755cbf",
   "metadata": {},
   "source": [
    "# Declare and Initialize TS Model Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a33b887-b266-4ff9-b2ca-a334364eb410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-05 08:02:26\n"
     ]
    }
   ],
   "source": [
    "date_col='Date'\n",
    "prediction_col=prediction_name\n",
    "feature_cols=[prediction_name]\n",
    "\n",
    "\n",
    "nLastData=input_sequence_length*2\n",
    "\n",
    "# dt_imported=datetime.now()\n",
    "dt_imported=datetime.now(timezone.utc)\n",
    "dtStr_imported=dt_imported.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(dtStr_imported)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ce645-c4c1-4b34-a56e-fd510aa1e66f",
   "metadata": {},
   "source": [
    "# Query Fin Data from BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2efe5184-5874-4464-9b82-14a38c804285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Last Record as starting point to retrive  sequence EMA1 over the past 60 day\n"
     ]
    }
   ],
   "source": [
    "print(f\"Check Last Record as starting point to retrive  sequence {prediction_col} over the past {input_sequence_length} day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b682d76-f7b1-45b2-92c1-78a5c0e7af38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "    select Date as LastDate  from `pongthorn.FinAssetForecast.fin_data` where Symbol='SPY' \n",
      "    and Date='2023-06-30'\n",
      "    \n",
      "     LastDate\n",
      "0  2023-06-30\n",
      "Forecast EMA1 movement of  SPY at 2023-06-30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lastDate=None\n",
    "if today=='':\n",
    "    sqlLastDate=f\"\"\" select max(Date) as LastDate  from `{table_data_id}` where Symbol='{asset_name}' \"\"\"\n",
    "\n",
    "else:\n",
    "    sqlLastDate=f\"\"\" \n",
    "    select Date as LastDate  from `{table_data_id}` where Symbol='{asset_name}' \n",
    "    and Date='{today}'\n",
    "    \"\"\"\n",
    "print(sqlLastDate)\n",
    "results = client.query(sqlLastDate)\n",
    "dfLastDate=results.to_dataframe()\n",
    "print(dfLastDate)\n",
    "if dfLastDate.empty:\n",
    "    print( f\"Not found price data at {today}  of {asset_name}\")\n",
    "    # return f\"Not found price data at {today}  of {asset_name}\"\n",
    "else:\n",
    "    lastDate=dfLastDate.iloc[0,0]\n",
    "    today=lastDate.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "print(f\"Forecast {prediction_col} movement of  {asset_name} at {today}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d4835aad-60d9-4c16-b69e-7da926e9ab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check whether SPY-EMA1 as 2023-06-30 was predicted the future for the next 10 days\n",
      "select prediction_date,asset_name,prediction_name,pred_timestamp from `pongthorn.FinAssetForecast.fin_movement_forecast` \n",
      "where prediction_date='2023-06-30' and   asset_name='SPY' and prediction_name='EMA1'\n",
      "order by pred_timestamp \n",
      "\n",
      "SPY-EMA1 at 2023-06-30 has not been predicted price movement yet.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Check whether {asset_name}-{prediction_col} as {today} was predicted the future for the next {output_sequence_length} days\")\n",
    "sqlLastPred=f\"\"\"select prediction_date,asset_name,prediction_name,pred_timestamp from `{table_id}` \n",
    "where prediction_date='{today}' and   asset_name='{asset_name}' and prediction_name='{prediction_col}'\n",
    "order by pred_timestamp \n",
    "\"\"\"\n",
    "print(sqlLastPred)\n",
    "dfLastPred=load_data_bq(sqlLastPred)\n",
    "if dfLastPred.empty==False:\n",
    "   dfLastPred=dfLastPred.drop_duplicates(subset=['prediction_date','asset_name','prediction_name'],keep='last') \n",
    "   print(f\"{asset_name}-{prediction_col}-{today} has been predicted price movement\")\n",
    "   print(dfLastPred)\n",
    "   # return f\"Prediction price movement of {asset_name}-{prediction_col} at {today} has been predicted\"\n",
    "else:\n",
    "       print(f\"{asset_name}-{prediction_col} at {today} has not been predicted price movement yet.\") \n",
    "       print(\"The system is about to predict price movement shortly.\") \n",
    "       print(\"=======================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "729b0f1f-020a-4c61-a80a-0403c6ecd9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data from 2023-03-02 - 2023-06-30 as input to forecast\n",
      "\n",
      "SELECT  *  FROM `pongthorn.FinAssetForecast.fin_data`  \n",
      "Where  Date between  DATE_SUB(DATE '2023-06-30', INTERVAL 120 DAY) \n",
      "and '2023-06-30' and Symbol='SPY' order by Date,ImportDateTime\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 84 entries, 2023-03-02 to 2023-06-30\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Symbol          84 non-null     object        \n",
      " 1   Close           84 non-null     float64       \n",
      " 2   EMA1            84 non-null     float64       \n",
      " 3   EMA2            84 non-null     float64       \n",
      " 4   MACD            84 non-null     float64       \n",
      " 5   SIGNAL          84 non-null     float64       \n",
      " 6   ImportDateTime  84 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(5), object(1)\n",
      "memory usage: 5.2+ KB\n",
      "None\n",
      "           Symbol   Close             ImportDateTime\n",
      "Date                                                \n",
      "2023-03-02    SPY  397.81 2023-06-09 09:03:44.544436\n",
      "2023-03-03    SPY  404.19 2023-06-09 09:03:44.544436\n",
      "2023-03-06    SPY  404.47 2023-06-09 09:03:44.544436\n",
      "2023-03-07    SPY  398.27 2023-06-09 09:03:44.544436\n",
      "2023-03-08    SPY  398.92 2023-06-09 09:03:44.544436\n",
      "           Symbol       Close             ImportDateTime\n",
      "Date                                                    \n",
      "2023-06-26    SPY  431.440002 2023-06-27 01:15:04.323693\n",
      "2023-06-27    SPY  436.170013 2023-06-28 01:15:04.758629\n",
      "2023-06-28    SPY  436.390015 2023-06-29 01:15:04.066850\n",
      "2023-06-29    SPY  438.109985 2023-06-30 01:15:04.233604\n",
      "2023-06-30    SPY  443.279999 2023-07-01 01:15:04.205584\n"
     ]
    }
   ],
   "source": [
    "dayAgo=datetime.strptime(today,'%Y-%m-%d') +timedelta(days=-nLastData)\n",
    "print(f\"Get data from {dayAgo.strftime('%Y-%m-%d')} - {today} as input to forecast\")\n",
    "\n",
    "sql=f\"\"\"\n",
    "SELECT  *  FROM `{table_data_id}`  \n",
    "Where  {date_col} between  DATE_SUB(DATE '{today}', INTERVAL {nLastData} DAY) \n",
    "and '{today}' and Symbol='{asset_name}' order by {date_col},ImportDateTime\n",
    "\"\"\"\n",
    "print(sql)\n",
    "query_result=client.query(sql)\n",
    "df=query_result.to_dataframe()\n",
    "\n",
    "df=df.drop_duplicates(subset=[date_col,'Symbol'],keep='last')\n",
    "df[date_col]=pd.to_datetime(df[date_col],format='%Y-%m-%d')\n",
    "df.set_index(date_col,inplace=True)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "print(df[['Symbol','Close' ,'ImportDateTime']].head())\n",
    "print(df[['Symbol','Close' ,'ImportDateTime']].tail())\n",
    "\n",
    "if df.empty==True or len(df)<input_sequence_length:\n",
    "    print(f\"There is no enough data to make prediction during {dayAgo.strftime('%Y-%m-%d')} - {today}\")\n",
    "    # return f\"There is no enough data to make prediction during {dayAgo.strftime('%Y-%m-%d')} - {today}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "327a7a76-24a7-4f8f-82c7-836c6a3778dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.dates as mdates\n",
    "# import seaborn as sns\n",
    "\n",
    "# plt.subplots(2, 1, figsize = (20, 10),sharex=True)\n",
    "\n",
    "# ax1 = plt.subplot(2, 1, 1)\n",
    "# plt.plot(df[['Close','EMA1','EMA2']])\n",
    "# plt.ylabel('Price & EMA')\n",
    "\n",
    "# ax2 = plt.subplot(2, 1, 2)\n",
    "# plt.plot(df[['MACD','SIGNAL']])\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('MACD & Signal')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546448a-234c-49d2-9a97-346a7e62ee25",
   "metadata": {},
   "source": [
    "# Get only Feature( 1 Indicator) to Predict itself in the next N days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "36d29f68-fa93-42fc-903a-20ac2cc556ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Feature to Predict : EMA1 \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 60 entries, 2023-04-05 to 2023-06-30\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   EMA1    60 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 960.0 bytes\n",
      "None\n",
      "(60, 1)\n",
      "                EMA1\n",
      "Date                \n",
      "2023-04-05  403.7406\n",
      "2023-04-06  404.7314\n",
      "2023-04-10  405.6184\n",
      "2023-04-11  406.3641\n",
      "2023-04-12  406.6707\n",
      "2023-04-13  407.9069\n",
      "2023-04-14  408.7347\n",
      "2023-04-17  409.6812\n",
      "2023-04-18  410.5046\n",
      "2023-04-19  411.1656\n",
      "                EMA1\n",
      "Date                \n",
      "2023-06-16  433.6472\n",
      "2023-06-20  434.2963\n",
      "2023-06-21  434.4133\n",
      "2023-06-22  434.7945\n",
      "2023-06-23  434.5035\n",
      "2023-06-26  433.9469\n",
      "2023-06-27  434.3545\n",
      "2023-06-28  434.7246\n",
      "2023-06-29  435.3401\n",
      "2023-06-30  436.7793\n"
     ]
    }
   ],
   "source": [
    "print(f\"Get Feature to Predict : {prediction_col} \")\n",
    "dfForPred=df[feature_cols]\n",
    "#dfForPred=dfForPred.iloc[-(input_sequence_length+1):-1,:]\n",
    "dfForPred=dfForPred.iloc[-input_sequence_length:,:]\n",
    "print(dfForPred.info())\n",
    "print(dfForPred.shape)\n",
    "\n",
    "print(dfForPred.head(10))\n",
    "print(dfForPred.tail(10))\n",
    "\n",
    "# dfForPred.plot(figsize = (20, 10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306df85-1fb9-4e9e-9987-e42d6e2c84f5",
   "metadata": {},
   "source": [
    "# Make Pediction as Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0866a254-f643-4772-a239-9ff5621f89d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 1)\n",
      "(1, 60, 1)\n",
      "1/1 [==============================] - 1s 891ms/step\n",
      "(1, 10) [[0.88172513 0.8705535  0.8742105  0.86745614 0.88415515 0.8758461\n",
      "  0.87507915 0.88143235 0.8743186  0.8755618 ]]\n",
      "(10, 1) [[440.05695]\n",
      " [436.8518 ]\n",
      " [437.901  ]\n",
      " [435.96317]\n",
      " [440.75412]\n",
      " [438.37024]\n",
      " [438.1502 ]\n",
      " [439.97293]\n",
      " [437.932  ]\n",
      " [438.28867]]\n",
      "============================Summary============================\n",
      "(60, 1)\n",
      "(10, 1)\n",
      "============================Input============================\n",
      "[[403.7406]\n",
      " [404.7314]\n",
      " [405.6184]\n",
      " [406.3641]\n",
      " [406.6707]\n",
      " [407.9069]\n",
      " [408.7347]\n",
      " [409.6812]\n",
      " [410.5046]\n",
      " [411.1656]\n",
      " [411.2955]\n",
      " [411.4599]\n",
      " [411.6727]\n",
      " [410.6558]\n",
      " [409.5111]\n",
      " [410.0382]\n",
      " [411.1094]\n",
      " [411.9095]\n",
      " [411.7151]\n",
      " [411.0432]\n",
      " [409.9681]\n",
      " [410.4521]\n",
      " [410.8681]\n",
      " [410.8793]\n",
      " [411.2376]\n",
      " [411.3999]\n",
      " [411.4344]\n",
      " [411.7209]\n",
      " [411.4535]\n",
      " [412.1401]\n",
      " [413.4292]\n",
      " [414.373 ]\n",
      " [415.1761]\n",
      " [414.9786]\n",
      " [414.2716]\n",
      " [414.3404]\n",
      " [415.373 ]\n",
      " [416.247 ]\n",
      " [416.5385]\n",
      " [417.4988]\n",
      " [419.3935]\n",
      " [420.7947]\n",
      " [422.1102]\n",
      " [422.9174]\n",
      " [424.0486]\n",
      " [425.1037]\n",
      " [426.7027]\n",
      " [428.5123]\n",
      " [430.0882]\n",
      " [432.3631]\n",
      " [433.6472]\n",
      " [434.2963]\n",
      " [434.4133]\n",
      " [434.7945]\n",
      " [434.5035]\n",
      " [433.9469]\n",
      " [434.3545]\n",
      " [434.7246]\n",
      " [435.3401]\n",
      " [436.7793]]\n",
      "============================Output============================\n",
      "[[440.05695]\n",
      " [436.8518 ]\n",
      " [437.901  ]\n",
      " [435.96317]\n",
      " [440.75412]\n",
      " [438.37024]\n",
      " [438.1502 ]\n",
      " [439.97293]\n",
      " [437.932  ]\n",
      " [438.28867]]\n"
     ]
    }
   ],
   "source": [
    "xUnscaled=dfForPred.values #print(xUnscaled.shape)\n",
    "xScaled=x_scaler.transform(xUnscaled)\n",
    "print(xScaled.shape)\n",
    "# print(xScaled[-5:])\n",
    "\n",
    "# # Way1\n",
    "# xScaledToPredict = []\n",
    "# xScaledToPredict.append(xScaled)\n",
    "# print(len(xScaledToPredict))\n",
    "\n",
    "# yPredScaled=x_model.predict(np.array(xScaledToPredict))\n",
    "# print(yPredScaled.shape,yPredScaled)\n",
    "\n",
    "# yPred  = x_scalerPred.inverse_transform(yPredScaled.reshape(-1, 1))\n",
    "# print(yPred.shape,yPred)\n",
    "\n",
    "#Way2\n",
    "xScaledToPredict= xScaled.reshape(1,input_sequence_length,len(feature_cols))\n",
    "print(xScaledToPredict.shape)\n",
    "\n",
    "yPredScaled = x_model.predict(xScaledToPredict)\n",
    "print(yPredScaled.shape, yPredScaled)\n",
    "\n",
    "yPred = x_scalerPred.inverse_transform(yPredScaled).reshape(-1, 1)\n",
    "print(yPred.shape, yPred)\n",
    "\n",
    "\n",
    "print(\"============================Summary============================\")\n",
    "print(xUnscaled.shape)\n",
    "print(yPred.shape)\n",
    "\n",
    "print(\"============================Input============================\")\n",
    "print(xUnscaled)\n",
    "print(\"============================Output============================\")\n",
    "print(yPred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a97710-b915-4d94-baec-9ffedca2ef73",
   "metadata": {},
   "source": [
    "# Build Prediction Result Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893eae3-3adf-4eb6-815a-df7905520da6",
   "metadata": {},
   "source": [
    "## Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9fb7d106-f6c2-47dd-99db-f764b8697e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create indexes from Dataframe dfForPred\n",
      "(60, 1)\n",
      "                EMA1\n",
      "Date                \n",
      "2023-04-05  403.7406\n",
      "2023-04-06  404.7314\n",
      "2023-04-10  405.6184\n",
      "2023-04-11  406.3641\n",
      "2023-04-12  406.6707\n",
      "                EMA1\n",
      "Date                \n",
      "2023-06-26  433.9469\n",
      "2023-06-27  434.3545\n",
      "2023-06-28  434.7246\n",
      "2023-06-29  435.3401\n",
      "2023-06-30  436.7793\n"
     ]
    }
   ],
   "source": [
    "print(\"Create indexes from Dataframe dfForPred\")\n",
    "dfFeature=pd.DataFrame(data= xUnscaled,columns=feature_cols,index=dfForPred.index)\n",
    "\n",
    "print(dfFeature.shape)\n",
    "print(dfFeature.head())\n",
    "print(dfFeature.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b51723-9516-4297-b40e-61cd1d6375e1",
   "metadata": {},
   "source": [
    "## Forecast/Prediction Value Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9c1f307-5e3e-4ea5-9e3f-fe614518819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create indexes by specifying output_sequence_length stating from get last record of DFFeature+1\n",
      "DatetimeIndex(['2023-07-03', '2023-07-05', '2023-07-06', '2023-07-07',\n",
      "               '2023-07-10', '2023-07-11', '2023-07-12', '2023-07-13',\n",
      "               '2023-07-14', '2023-07-17'],\n",
      "              dtype='datetime64[ns]', freq='C')\n",
      "(10, 1)\n",
      "                  EMA1\n",
      "Date                  \n",
      "2023-07-03  440.056946\n",
      "2023-07-05  436.851807\n",
      "2023-07-06  437.901001\n",
      "2023-07-07  435.963165\n",
      "2023-07-10  440.754120\n",
      "2023-07-11  438.370239\n",
      "2023-07-12  438.150208\n",
      "2023-07-13  439.972931\n",
      "2023-07-14  437.932007\n",
      "2023-07-17  438.288666\n"
     ]
    }
   ],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "\n",
    "print(\"Create indexes by specifying output_sequence_length stating from get last record of DFFeature+1\")\n",
    "lastRowOfFeature=dfFeature.index.max()\n",
    "firstRowofPrediction=lastRowOfFeature+timedelta(days=1)\n",
    "datePred=pd.date_range(start=firstRowofPrediction,freq=us_bd,periods=output_sequence_length)\n",
    "print(datePred)\n",
    "\n",
    "dfPrediction=pd.DataFrame(data= yPred,columns=feature_cols,index=datePred)\n",
    "dfPrediction.index.name=date_col\n",
    "print(dfPrediction.shape)\n",
    "print(dfPrediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e321c-4fa0-4d78-8678-99b9b925a2ec",
   "metadata": {},
   "source": [
    "# Get Prepraed To ingest data into BQ , we have to create dataframe and convert to Json-Rowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bbf27cb7-663b-4b63-866e-547b3a4e45e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   prediction_date  1 non-null      object\n",
      " 1   asset_name       1 non-null      object\n",
      " 2   prediction_name  1 non-null      object\n",
      " 3   pred_timestamp   1 non-null      object\n",
      " 4   model_id         1 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 168.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_date</th>\n",
       "      <th>asset_name</th>\n",
       "      <th>prediction_name</th>\n",
       "      <th>pred_timestamp</th>\n",
       "      <th>model_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>SPY</td>\n",
       "      <td>EMA1</td>\n",
       "      <td>2023-07-05 08:02:26</td>\n",
       "      <td>spy-ema1-60t10-ds0115t0523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prediction_date asset_name prediction_name       pred_timestamp  \\\n",
       "0      2023-06-30        SPY            EMA1  2023-07-05 08:02:26   \n",
       "\n",
       "                     model_id  \n",
       "0  spy-ema1-60t10-ds0115t0523  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputDF=pd.DataFrame(data=[ [today,asset_name,prediction_col,dtStr_imported,model_id] ],columns=[\"prediction_date\",\"asset_name\",\"prediction_name\",\"pred_timestamp\",\"model_id\"])\n",
    "print(outputDF.info())\n",
    "outputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c89e2d97-1f3d-41bf-9b50-e22e94ef8457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prediction_date': '2023-06-30',\n",
       "  'asset_name': 'SPY',\n",
       "  'prediction_name': 'EMA1',\n",
       "  'pred_timestamp': '2023-07-05 08:02:26',\n",
       "  'model_id': 'spy-ema1-60t10-ds0115t0523',\n",
       "  'feature_for_prediction': [{'input_date': '2023-04-05',\n",
       "    'input_feature': 403.7406},\n",
       "   {'input_date': '2023-04-06', 'input_feature': 404.7314},\n",
       "   {'input_date': '2023-04-10', 'input_feature': 405.6184},\n",
       "   {'input_date': '2023-04-11', 'input_feature': 406.3641},\n",
       "   {'input_date': '2023-04-12', 'input_feature': 406.6707},\n",
       "   {'input_date': '2023-04-13', 'input_feature': 407.9069},\n",
       "   {'input_date': '2023-04-14', 'input_feature': 408.7347},\n",
       "   {'input_date': '2023-04-17', 'input_feature': 409.6812},\n",
       "   {'input_date': '2023-04-18', 'input_feature': 410.5046},\n",
       "   {'input_date': '2023-04-19', 'input_feature': 411.1656},\n",
       "   {'input_date': '2023-04-20', 'input_feature': 411.2955},\n",
       "   {'input_date': '2023-04-21', 'input_feature': 411.4599},\n",
       "   {'input_date': '2023-04-24', 'input_feature': 411.6727},\n",
       "   {'input_date': '2023-04-25', 'input_feature': 410.6558},\n",
       "   {'input_date': '2023-04-26', 'input_feature': 409.5111},\n",
       "   {'input_date': '2023-04-27', 'input_feature': 410.0382},\n",
       "   {'input_date': '2023-04-28', 'input_feature': 411.1094},\n",
       "   {'input_date': '2023-05-01', 'input_feature': 411.9095},\n",
       "   {'input_date': '2023-05-02', 'input_feature': 411.7151},\n",
       "   {'input_date': '2023-05-03', 'input_feature': 411.0432},\n",
       "   {'input_date': '2023-05-04', 'input_feature': 409.9681},\n",
       "   {'input_date': '2023-05-05', 'input_feature': 410.4521},\n",
       "   {'input_date': '2023-05-08', 'input_feature': 410.8681},\n",
       "   {'input_date': '2023-05-09', 'input_feature': 410.8793},\n",
       "   {'input_date': '2023-05-10', 'input_feature': 411.2376},\n",
       "   {'input_date': '2023-05-11', 'input_feature': 411.3999},\n",
       "   {'input_date': '2023-05-12', 'input_feature': 411.4344},\n",
       "   {'input_date': '2023-05-15', 'input_feature': 411.7209},\n",
       "   {'input_date': '2023-05-16', 'input_feature': 411.4535},\n",
       "   {'input_date': '2023-05-17', 'input_feature': 412.1401},\n",
       "   {'input_date': '2023-05-18', 'input_feature': 413.4292},\n",
       "   {'input_date': '2023-05-19', 'input_feature': 414.373},\n",
       "   {'input_date': '2023-05-22', 'input_feature': 415.1761},\n",
       "   {'input_date': '2023-05-23', 'input_feature': 414.9786},\n",
       "   {'input_date': '2023-05-24', 'input_feature': 414.2716},\n",
       "   {'input_date': '2023-05-25', 'input_feature': 414.3404},\n",
       "   {'input_date': '2023-05-26', 'input_feature': 415.373},\n",
       "   {'input_date': '2023-05-30', 'input_feature': 416.247},\n",
       "   {'input_date': '2023-05-31', 'input_feature': 416.5385},\n",
       "   {'input_date': '2023-06-01', 'input_feature': 417.4988},\n",
       "   {'input_date': '2023-06-02', 'input_feature': 419.3935},\n",
       "   {'input_date': '2023-06-05', 'input_feature': 420.7947},\n",
       "   {'input_date': '2023-06-06', 'input_feature': 422.1102},\n",
       "   {'input_date': '2023-06-07', 'input_feature': 422.9174},\n",
       "   {'input_date': '2023-06-08', 'input_feature': 424.0486},\n",
       "   {'input_date': '2023-06-09', 'input_feature': 425.1037},\n",
       "   {'input_date': '2023-06-12', 'input_feature': 426.7027},\n",
       "   {'input_date': '2023-06-13', 'input_feature': 428.5123},\n",
       "   {'input_date': '2023-06-14', 'input_feature': 430.0882},\n",
       "   {'input_date': '2023-06-15', 'input_feature': 432.3631},\n",
       "   {'input_date': '2023-06-16', 'input_feature': 433.6472},\n",
       "   {'input_date': '2023-06-20', 'input_feature': 434.2963},\n",
       "   {'input_date': '2023-06-21', 'input_feature': 434.4133},\n",
       "   {'input_date': '2023-06-22', 'input_feature': 434.7945},\n",
       "   {'input_date': '2023-06-23', 'input_feature': 434.5035},\n",
       "   {'input_date': '2023-06-26', 'input_feature': 433.9469},\n",
       "   {'input_date': '2023-06-27', 'input_feature': 434.3545},\n",
       "   {'input_date': '2023-06-28', 'input_feature': 434.7246},\n",
       "   {'input_date': '2023-06-29', 'input_feature': 435.3401},\n",
       "   {'input_date': '2023-06-30', 'input_feature': 436.7793}],\n",
       "  'prediction_result': [{'output_date': '2023-07-03',\n",
       "    'output_value': 440.0569458008},\n",
       "   {'output_date': '2023-07-05', 'output_value': 436.8518066406},\n",
       "   {'output_date': '2023-07-06', 'output_value': 437.9010009766},\n",
       "   {'output_date': '2023-07-07', 'output_value': 435.9631652832},\n",
       "   {'output_date': '2023-07-10', 'output_value': 440.754119873},\n",
       "   {'output_date': '2023-07-11', 'output_value': 438.3702392578},\n",
       "   {'output_date': '2023-07-12', 'output_value': 438.1502075195},\n",
       "   {'output_date': '2023-07-13', 'output_value': 439.9729309082},\n",
       "   {'output_date': '2023-07-14', 'output_value': 437.9320068359},\n",
       "   {'output_date': '2023-07-17', 'output_value': 438.2886657715}]}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonOutput = json.loads(outputDF.to_json(orient = 'records'))\n",
    "for item in jsonOutput:\n",
    "    \n",
    "    dataFeature=dfFeature.reset_index()[[date_col,prediction_col]]\n",
    "    dataFeature[date_col]=dataFeature[date_col].dt.strftime('%Y-%m-%d')\n",
    "    dataFeature.columns=[\"input_date\",\"input_feature\"]\n",
    "    jsonFeature= json.loads(dataFeature.to_json(orient = 'records'))\n",
    "    item[\"feature_for_prediction\"]=jsonFeature\n",
    "    \n",
    "    dataPred=dfPrediction.reset_index()[[date_col,prediction_col]]\n",
    "    dataPred[date_col]=dataPred[date_col].dt.strftime('%Y-%m-%d')\n",
    "    dataPred.columns=[\"output_date\",\"output_value\"]\n",
    "    jsonPred= json.loads(dataPred.to_json(orient = 'records'))\n",
    "    item[\"prediction_result\"]=jsonPred\n",
    " \n",
    "with open(\"fin_prediction.json\", \"w\") as outfile:\n",
    "    json.dump(jsonOutput, outfile)\n",
    "jsonOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061e560-fba8-478e-8eb3-70e2922ec302",
   "metadata": {},
   "source": [
    "# Ingest Data to BigQuery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bf9c75db-619f-4cf1-be6f-c63d498cc957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table pongthorn.FinAssetForecast.fin_movement_forecast already exists.\n",
      "[SchemaField('prediction_result', 'RECORD', 'REPEATED', None, None, (SchemaField('output_value', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('output_date', 'DATE', 'NULLABLE', None, None, (), None)), None), SchemaField('prediction_date', 'DATE', 'NULLABLE', None, None, (), None), SchemaField('feature_for_prediction', 'RECORD', 'REPEATED', None, None, (SchemaField('input_feature', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('input_date', 'DATE', 'NULLABLE', None, None, (), None)), None), SchemaField('pred_timestamp', 'TIMESTAMP', 'NULLABLE', None, None, (), None), SchemaField('prediction_name', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('asset_name', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('model_id', 'STRING', 'NULLABLE', None, None, (), None)]\n",
      "import to bigquery successfully  1 records\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    table=client.get_table(table_id)\n",
    "    print(\"Table {} already exists.\".format(table_id))\n",
    "    print(table.schema)\n",
    "except Exception as ex :\n",
    "    print(str(ex))\n",
    "#if error  please create table and other configuration as  bq_prediction.txt    \n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "# schema=[  ]\n",
    ")\n",
    "\n",
    "job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND  \n",
    "#job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "job = client.load_table_from_json(jsonOutput,table_id, job_config = job_config)\n",
    "if job.errors is not None:\n",
    "    print(job.error_result)\n",
    "    print(job.errors)\n",
    "else:\n",
    "    print(f\"Import to bigquery successfully  {len(jsonOutput)} records\")\n",
    "    \n",
    "#job_config.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8e3a9e58-62e1-46cf-a25e-1774d45dfee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return   f\"The system has done predicting price movement of {asset_name}-{prediction_col}-{today}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef245de-ad6a-4315-8505-2c1fdba16af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467828a9-b291-4816-b1a2-26e63855b046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116348e-3b7a-4216-9283-191c97652b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
